{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "silent-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-blair",
   "metadata": {},
   "source": [
    "We often deal with real life problems of choosing between different sets of things. For eg, whether we want to buy something or not, is it going to be sunny, windy or rainy today? All these come under the gambit of classification, predicting which set of particular data point belongs.\n",
    "<p>\n",
    "Linear classification is the means by which classification is made based on predictor function that is linear, combining weights with the values of dependent variable. Non- linear operations may be involved in this process.<br>\n",
    "<img src=\"https://miro.medium.com/max/2240/1*wFOWSUKXt95qoBfv97HAkg.jpeg\">\n",
    "\n",
    "In the above two equations, Eq 1 associates each feature with a weight. The reason why we call logistic regression one of the generalized linear model. Following which there is a use of link function(explanation will be provided below) that converts the data provided within the range of (0,1).Here Eq 2. is the link function which is a sigmoid function and z is a value that gives you the probability of one of the events happening.<p>\n",
    "\n",
    "### Logistic Regression process\n",
    "Given a data(X,Y), X being a matrix of values with m examples and n features and Y being a vector with m examples. The objective is to train the model to predict which class the future values belong to. Primarily, we create a weight matrix with random initialization. Then we multiply it by features.<p><img src=\"https://miro.medium.com/max/374/1*zgHJk04MnT-KHseMx5UplA.gif\"><p>\n",
    "We then pass the output obtained from Eq 1. to a link function.<p>\n",
    "<img src=\"https://miro.medium.com/max/192/1*W-eV7ojoYq8FKTHrDyxKEw.gif\"><p>\n",
    "This is followed by calculating the cost for that iteration whose formula is:<p>\n",
    "<img src=\"https://miro.medium.com/max/618/1*oWzox2Raoi-HkqEAkdgJuA.gif\"><p>\n",
    "The derivative of this cost is calculated following which the weights are updated.   \n",
    "<br><img src=\"https://miro.medium.com/max/225/1*fBcG0OClMcbvR704jynxfQ.gif\"><br>Gradient<p>\n",
    "<img src=\"https://miro.medium.com/max/231/1*zbGFw_u7ay1UagAPkE6PMw.gif\"><br>Update<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thousand-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The entire code in Python for Logistic Regression from scratch:\n",
    "\n",
    "class log_reg:\n",
    "    def __init__(self, iterations, alpha):\n",
    "        self.iterations = iterations   #choosing number of iterations (Hyperparameter)\n",
    "        self.alpha = alpha             #choosing alpha (Hyperparameter)\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return(1/1+np.exp(-z))         #Sigmoid (link function)\n",
    "    \n",
    "    def fit(x,y, self):                #(X-data for training, y-output)\n",
    "        m=x.shape[0]\n",
    "        w=np.random.randn(shape[1],1)  #Initializing the weight\n",
    "        \n",
    "        cost_=[]\n",
    "        for i in len(iterations):      #for each number of iterations\n",
    "            a = np.dot(x,w)            #multiplying the weights with the Feature values and summing them up\n",
    "            z = self.sigmoid(a)        #using link function to transform the data\n",
    "            \n",
    "            cost=(-1/m)*(np.dot(log(z))+(np.dot(1-y),np.log(1-z))) #Calculating the cost function\n",
    "            cost_.append[cost]         #creating a list with all cost values for each iteration\n",
    "            dw=(1/m)*np.dot(x.T,(z-y)) #calculating the gradient\n",
    "            \n",
    "            w=w-(self.alpha*dw)        #updating the weights\n",
    "            \n",
    "            return self\n",
    "        \n",
    "        def predict(self, x, threshold):\n",
    "            probability=self.sigmoid(np.dot(x,self.w)) #predicting a new set of values based on the training\n",
    "            if(probability>threshold):\n",
    "                return(1, probability)\n",
    "            else:\n",
    "                return(0, probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-capacity",
   "metadata": {},
   "source": [
    "### Math and Intuition behind Logistic Regression\n",
    "The goal of the logistic regression algorithm is to create a linear decision boundary separating two classes from one another. This decision boundary is given by a conditional probability.\n",
    "<br><img src=\"https://miro.medium.com/max/944/1*zwJSij87fzcsbT6-pT4SQw.png\"><br>The line in between is the decision boundary with two classes above and below it.<p>\n",
    "Let us assume that the class above the black line(decision boundary) i.e. the ‘+’ is classified as ‘1’ and class below the decision boundary ‘o’ is defined as ‘0’. What logistic regression does is that it calculates a conditional probability i.e.<p>\n",
    "<img src=\"https://miro.medium.com/max/164/1*FU0Nigzvpemy3MJUlxGUqw.gif\"><br>Probability for class ‘1’<p>\n",
    "<img src=\"https://miro.medium.com/max/164/1*qqKpGBJkxelSyExgOUFgew.gif\"><br>Probability for class ‘0’<p>\n",
    "Logistic regression calculates the probability of a particular set of data points belonging to either of those class’ given the value of x and w. The logic is that say, we have a set of values that we obtain from negative infinity to positive infinity based on the linear model, we need to narrow it down to a score that is in between zero and one as probabilities always are in that range and logistic regression talks about probabilities. The link function, sigmoid function takes care of this work.<p>\n",
    "The use of exponent in the sigmoid function is justified as probability is always greater than zero and the property of exponents takes care of this aspect. Then we need to worry about the limiting the values less than one, which is done by dividing the value in the numerator by value greater than it.<p>\n",
    "<img src=\"https://miro.medium.com/max/203/1*jQuR6pcfDoBfgnC0EM9nOA.gif\"><br>Probability greater than 0<p>\n",
    "<img src=\"https://miro.medium.com/max/420/1*Iet19xnD9S5E5xv863CimQ.gif\"><br>Probability greater than 0 and less than 1<p>\n",
    "Now to get the probability of the alternate class we just have to subtract the value obtained above by 1. When we divide the above equation by the numerator term, we obtain the sigmoid link function.\n",
    "<p><img src=\"https://miro.medium.com/max/297/1*ZqLdj1Uohg0AykU03IuKXA.gif\"><p>\n",
    "### Odds Ratio\n",
    "We hear the term “what are the odds of a team winning”, from many people around us. Odds is basically the probability of an event occurring to that of an event not occurring. In logistic regression, the odds of an event occurring can be given by the formula:\n",
    "<p><img src=\"https://miro.medium.com/max/318/1*hWQGnNaeVX4TgV1g6-C8bA.gif\"><br>Odds of an event occurring<p>\n",
    "The log odds or log-likelihood of the event is given by taking log of the above equation. The odds ratio is log transformed to remove the restricted range as probabilities are in the range (0,1).Log transformation changes this to values from negative infinity to positive infinity. The second reason is that log values are easier to interpret.\n",
    "<p><img src=\"https://miro.medium.com/max/414/1*fANFmXlXhvcP8bXalhx8Sw.gif\"><br>Log(odds)<p>\n",
    "If we take into consideration the conditional probability of getting an output P(y=1|x;w) is equal to the sigmoid function and the p(y=0|x;w) = 1-p(y=0|x;w) and if take in that our sample has a Bernoulli distribution then the cost function for the logistic regression model is derived by,\n",
    "<p><img src=\"https://miro.medium.com/max/554/1*u3HtNCoEiG7Z2yFr6uYOsQ.gif\"><p>\n",
    "Taking log this equation can be transformed into the cost function above. The presence of the minus sign in the beginning of the function is to ensure we try minimizing the negative of likelihood instead of maximizing the value as gradient descent minimizes the error.\n",
    "The Scikit-learn implementation of logistic regression is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convenient-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confident-butler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_hair</th>\n",
       "      <th>forehead_width_cm</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>nose_wide</th>\n",
       "      <th>nose_long</th>\n",
       "      <th>lips_thin</th>\n",
       "      <th>distance_nose_to_lip_long</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
       "0          0               14.0                 5.4          0          0   \n",
       "1          0               11.8                 6.3          1          1   \n",
       "2          0               14.4                 6.1          0          1   \n",
       "3          1               13.5                 5.9          0          0   \n",
       "4          1               13.0                 6.8          1          1   \n",
       "\n",
       "   lips_thin  distance_nose_to_lip_long  gender  \n",
       "0          1                          0  Female  \n",
       "1          1                          1    Male  \n",
       "2          1                          1    Male  \n",
       "3          0                          0  Female  \n",
       "4          1                          1    Male  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['long_hair', 'forehead_width_cm','forehead_height_cm','nose_wide','nose_long','lips_thin','distance_nose_to_lip_long','gender']\n",
    "foo = pd.read_csv('gender_classification_v7.csv', names = col, header=1)\n",
    "foo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "realistic-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_hair</th>\n",
       "      <th>forehead_width_cm</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>nose_wide</th>\n",
       "      <th>nose_long</th>\n",
       "      <th>lips_thin</th>\n",
       "      <th>distance_nose_to_lip_long</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1</td>\n",
       "      <td>13.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
       "4995          1               13.6                 5.1          0          0   \n",
       "4996          1               11.9                 5.4          0          0   \n",
       "4997          1               12.9                 5.7          0          0   \n",
       "4998          1               13.2                 6.2          0          0   \n",
       "4999          1               15.4                 5.4          1          1   \n",
       "\n",
       "      lips_thin  distance_nose_to_lip_long  gender  \n",
       "4995          0                          0  Female  \n",
       "4996          0                          0  Female  \n",
       "4997          0                          0  Female  \n",
       "4998          0                          0  Female  \n",
       "4999          1                          1    Male  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comfortable-lawrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "long_hair                    5000\n",
       "forehead_width_cm            5000\n",
       "forehead_height_cm           5000\n",
       "nose_wide                    5000\n",
       "nose_long                    5000\n",
       "lips_thin                    5000\n",
       "distance_nose_to_lip_long    5000\n",
       "gender                       5000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excessive-principle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_hair</th>\n",
       "      <th>forehead_width_cm</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>nose_wide</th>\n",
       "      <th>nose_long</th>\n",
       "      <th>lips_thin</th>\n",
       "      <th>distance_nose_to_lip_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.869600</td>\n",
       "      <td>13.181760</td>\n",
       "      <td>5.946280</td>\n",
       "      <td>0.493800</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.336777</td>\n",
       "      <td>1.107067</td>\n",
       "      <td>0.541318</td>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.499986</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.500049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         long_hair  forehead_width_cm  forehead_height_cm    nose_wide  \\\n",
       "count  5000.000000        5000.000000         5000.000000  5000.000000   \n",
       "mean      0.869600          13.181760            5.946280     0.493800   \n",
       "std       0.336777           1.107067            0.541318     0.500012   \n",
       "min       0.000000          11.400000            5.100000     0.000000   \n",
       "25%       1.000000          12.200000            5.500000     0.000000   \n",
       "50%       1.000000          13.100000            5.900000     0.000000   \n",
       "75%       1.000000          14.000000            6.400000     1.000000   \n",
       "max       1.000000          15.500000            7.100000     1.000000   \n",
       "\n",
       "         nose_long    lips_thin  distance_nose_to_lip_long  \n",
       "count  5000.000000  5000.000000                5000.000000  \n",
       "mean      0.508000     0.493000                   0.498800  \n",
       "std       0.499986     0.500001                   0.500049  \n",
       "min       0.000000     0.000000                   0.000000  \n",
       "25%       0.000000     0.000000                   0.000000  \n",
       "50%       1.000000     0.000000                   0.000000  \n",
       "75%       1.000000     1.000000                   1.000000  \n",
       "max       1.000000     1.000000                   1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "viral-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='long_hair', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPVUlEQVR4nO3df6xfdX3H8eeLIuLiD9DeMW1hl81mpmbzxzrEuRgnGyDbLCH+wMzZYbNuGZuabHO6P4aiJJr9YP6OZKBAjMh0CnNG06DoZkQoE5XCCHcgox3QSiuKTrbie398P3Vf2t5+vpSe+73lPh/JN/ec9/mcc943KffF+flNVSFJ0v4cNu0GJEmLn2EhSeoyLCRJXYaFJKnLsJAkdR0+7QaGsHz58pqdnZ12G5J0SLn++uu/XVUz+1r2qAyL2dlZNm3aNO02JOmQkuSO+ZZ5GkqS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktT1qHyCW3o0+89zf37aLWgROu4vvzno9j2ykCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6Bg+LJMuSfC3Jp9v88Um+mmQuyceSHNHqj23zc2357Ng23tzqtyQ5ZeieJUkPtRBHFq8Hbh6bfydwflU9HdgJrG/19cDOVj+/jSPJauBM4JnAqcD7kyxbgL4lSc2gYZFkJfAbwN+3+QAvBj7ehlwMnN6m17Z52vKT2vi1wGVV9UBV3Q7MAScM2bck6aGGPrL4O+CNwI/a/FOA71TVrja/BVjRplcAdwK05fe18T+u72OdH0uyIcmmJJu2b99+kH8NSVraBguLJL8JbKuq64fax7iquqCq1lTVmpmZmYXYpSQtGUN+U94LgJcmOQ04Engi8C7gqCSHt6OHlcDWNn4rcCywJcnhwJOAe8fqu42vI0laAIMdWVTVm6tqZVXNMrpA/fmq+m3gC8DL2rB1wBVt+so2T1v++aqqVj+z3S11PLAKuHaoviVJe5vGd3D/OXBZkrcDXwMubPULgUuTzAE7GAUMVbU5yeXATcAu4OyqenDh25akpWtBwqKqrgaubtO3sY+7marqh8DL51n/POC84TqUJO2PT3BLkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkrsHCIsmRSa5N8vUkm5O8tdWPT/LVJHNJPpbkiFZ/bJufa8tnx7b15la/JckpQ/UsSdq3IY8sHgBeXFXPAp4NnJrkROCdwPlV9XRgJ7C+jV8P7Gz189s4kqwGzgSeCZwKvD/JsgH7liTtYbCwqJH72+xj2qeAFwMfb/WLgdPb9No2T1t+UpK0+mVV9UBV3Q7MAScM1bckaW+DXrNIsizJDcA2YCPwH8B3qmpXG7IFWNGmVwB3ArTl9wFPGa/vY53xfW1IsinJpu3btw/w20jS0jVoWFTVg1X1bGAlo6OBZwy4rwuqak1VrZmZmRlqN5K0JC3I3VBV9R3gC8DzgaOSHN4WrQS2tumtwLEAbfmTgHvH6/tYR5K0AIa8G2omyVFt+nHArwM3MwqNl7Vh64Ar2vSVbZ62/PNVVa1+Zrtb6nhgFXDtUH1LkvZ2eH/IAXsqcHG7c+kw4PKq+nSSm4DLkrwd+BpwYRt/IXBpkjlgB6M7oKiqzUkuB24CdgFnV9WDA/YtSdrDYGFRVd8AnrOP+m3s426mqvoh8PJ5tnUecN7B7lGSNBmf4JYkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1TRQWSa6apCZJenTa79eqJjkS+AlgeZKjgbRFTwRWDNybJGmR6H0H9+8DbwCeBlzP/4fFd4H3DteWJGkx2W9YVNW7gHcl+eOqes8C9SRJWmR6RxYAVNV7kvwyMDu+TlVdMlBfkqRFZKKwSHIp8LPADcCDrVyAYSFJS8BEYQGsAVZXVQ3ZjCRpcZr0OYsbgZ8ashFJ0uI16ZHFcuCmJNcCD+wuVtVLB+lKkrSoTBoWbxmyCUnS4jbp3VBfHLoRSdLiNendUN9jdPcTwBHAY4DvV9UTh2pMkrR4THpk8YTd00kCrAVOHKopSdLi8rDfOlsjnwJOOfjtSJIWo0lPQ50xNnsYo+cufjhIR5KkRWfSu6F+a2x6F/AtRqeiJElLwKTXLM4auhFJ0uI16ZcfrUzyySTb2ucTSVYO3ZwkaXGY9AL3h4ArGX2vxdOAf2o1SdISMGlYzFTVh6pqV/t8GJgZsC9J0iIyaVjcm+TVSZa1z6uBe4dsTJK0eEwaFq8FXgHcDdwFvAz43f2tkOTYJF9IclOSzUle3+pPTrIxya3t59GtniTvTjKX5BtJnju2rXVt/K1J1h3A7ylJegQmDYtzgXVVNVNVP8koPN7aWWcX8CdVtZrR095nJ1kNvAm4qqpWAVe1eYCXAKvaZwPwARiFC3AO8DzgBOCc3QEjSVoYk4bFL1TVzt0zVbUDeM7+Vqiqu6rq39r094CbgRWMns+4uA27GDi9Ta8FLmlPiF8DHJXkqYyeFN9YVTtaDxuBUyfsW5J0EEwaFoeN/998+7/9SR/oI8kso3D5KnBMVd3VFt0NHNOmVwB3jq22pdXmq0uSFsikf/D/BvhKkn9o8y8HzptkxSSPBz4BvKGqvjt6D+FIVVWSg/JVrUk2MDp9xXHHHXcwNilJaiY6sqiqS4AzgHva54yqurS3XpLHMAqKj1TVP7byPe30Eu3ntlbfChw7tvrKVpuvvmePF1TVmqpaMzPjXb2SdDBN/NbZqrqpqt7bPjf1xrdXmV8I3FxVfzu26Epg9x1N64ArxuqvaXdFnQjc105XfQ44OcnR7VTYya0mSVogE193OAAvAH4H+GaSG1rtL4B3AJcnWQ/cweiWXIDPAKcBc8APgLNgdDE9yduA69q4c9sFdknSAhksLKrqX4HMs/ikfYwv4Ox5tnURcNHB606S9HA87C8/kiQtPYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXYGGR5KIk25LcOFZ7cpKNSW5tP49u9SR5d5K5JN9I8tyxdda18bcmWTdUv5Kk+Q15ZPFh4NQ9am8CrqqqVcBVbR7gJcCq9tkAfABG4QKcAzwPOAE4Z3fASJIWzmBhUVVfAnbsUV4LXNymLwZOH6tfUiPXAEcleSpwCrCxqnZU1U5gI3sHkCRpYAt9zeKYqrqrTd8NHNOmVwB3jo3b0mrz1feSZEOSTUk2bd++/eB2LUlL3NQucFdVAXUQt3dBVa2pqjUzMzMHa7OSJBY+LO5pp5doP7e1+lbg2LFxK1ttvrokaQEtdFhcCey+o2kdcMVY/TXtrqgTgfva6arPAScnObpd2D651SRJC+jwoTac5KPAi4DlSbYwuqvpHcDlSdYDdwCvaMM/A5wGzAE/AM4CqKodSd4GXNfGnVtVe140lyQNbLCwqKpXzbPopH2MLeDsebZzEXDRQWxNkvQw+QS3JKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkrsHeDXWo+8U/u2TaLWgRuv6vXjPtFqSp8MhCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXIRMWSU5NckuSuSRvmnY/krSUHBJhkWQZ8D7gJcBq4FVJVk+3K0laOg6JsABOAOaq6raq+h/gMmDtlHuSpCXj8Gk3MKEVwJ1j81uA540PSLIB2NBm709yywL1thQsB7497SYWg/z1umm3oIfy3+Zu5+RgbOWn51twqIRFV1VdAFww7T4ejZJsqqo10+5D2pP/NhfOoXIaaitw7Nj8ylaTJC2AQyUsrgNWJTk+yRHAmcCVU+5JkpaMQ+I0VFXtSvJHwOeAZcBFVbV5ym0tJZ7e02Llv80Fkqqadg+SpEXuUDkNJUmaIsNCktRlWGi/fM2KFqMkFyXZluTGafeyVBgWmpevWdEi9mHg1Gk3sZQYFtofX7OiRamqvgTsmHYfS4lhof3Z12tWVkypF0lTZFhIkroMC+2Pr1mRBBgW2j9fsyIJMCy0H1W1C9j9mpWbgct9zYoWgyQfBb4C/FySLUnWT7unRztf9yFJ6vLIQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJDmkeT+BdrPW5L86cNc5zNJjhqoJWkvh8R3cEt6qKo6bc9akjB6dupHU2hJj3IeWUgdGfmrJDcm+WaSV7b6i5JcneTjSf49yUfaH2ySnNZq1yd5d5JPd3azum3rtiSvG9v3p9o2NifZMFb/VpLlSWbbl1NdAtzIQ9/lJR00HllIfWcAzwaeBSwHrkvypbbsOcAzgf8Cvgy8IMkm4IPAC6vq9vZqip5nAL8KPAG4JckHqup/gddW1Y4kj2v7/URV3bvHuquAdVV1zSP7NaX5eWQh9f0K8NGqerCq7gG+CPxSW3ZtVW1pp35uAGYZ/eG/rapub2MmCYt/rqoHqurbwDbgmFZ/XZKvA9cwOmpYtY917zAoNDSPLKRH5oGx6Qc58P+m9tpOkhcBvwY8v6p+kORq4Mh9rPv9A9ynNDGPLKS+fwFemWRZkhnghcC1+xl/C/AzSWbb/CsPcL9PAna2oHgGcOIBbkd6xDyykPo+CTwf+DpQwBur6u72B3wvVfXfSf4Q+GyS7zP6XpAD8VngD5LczCiAPNWkqfEV5dIAkjy+qu5vd0e9D7i1qs6fdl/SgfI0lDSM30tyA7CZ0emkD063HemR8chCWiBJzgJev0f5y1V19jT6kR4Ow0KS1OVpKElSl2EhSeoyLCRJXYaFJKnr/wB0FNWlDfpL5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(foo['long_hair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "technical-bullet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='long_hair', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(foo['long_hair'], hue=foo['distance_nose_to_lip_long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "concerned-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['long_hair', 'forehead_width_cm', 'forehead_height_cm', 'nose_wide','nose_long','lips_thin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rental-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = foo[feature]\n",
    "y = foo.distance_nose_to_lip_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lonely-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "noble-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "circular-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lightweight-sucking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mexican-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "polish-cemetery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8504"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "democratic-dragon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    629\n",
       "1    621\n",
       "Name: distance_nose_to_lip_long, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "limiting-chosen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4968"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "located-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Gender :      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, array([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"True Gender :      \"), y_test.values[15:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "published-mobility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Gender : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, array([0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Predicted Gender : \"), y_pred[15:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "local-lending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[541,  88],\n",
       "       [ 99, 522]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "systematic-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405797101449275"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
